import re 
import matplotlib.pyplot as plt 
import pandas as pd 
import numpy as np 
import seaborn as sns 
import altair as alt 
import plotly.express as px 
import xlrd 
import pandas as pd 
import warnings 
warnings.filterwarnings("ignore") 
import datetime 
np.random.seed(42) 
df = pd.read_excel("online_retail_data.xlsx", sheet_name = ["Year 2009-2010", 
"Year 2010-2011"]) 
fig, ax = plt.subplots(11, 4, figsize=(18,20)) 
axes_ = [axes_row for axes in ax for axes_row in axes] 
for i, c in enumerate(countries): 
sns.violinplot(x = "Price", data = data[data["Country"] == c], ax = axes_[i], 
inner = "point", palette = "pastel") 
axes_[i].set_title(c + ' ' + "Price Distribution") 
plt.tight_layout()
#Total Number of Unique Invoices 
len(data["Invoice"].unique()) 
import lifetimes 
rfm_summary = lifetimes.utils.summary_data_from_transaction_data(data, 
"Customer ID", "InvoiceDate", "Total Amount") 
rfm_summary.reset_index(inplace = True) 
from lifetimes.plotting 
import plot_frequency_recency_matrix 
from lifetimes.plotting 
import plot_probability_alive_matrix 
from lifetimes.plotting 
import plot_period_transactions 
from lifetimes.utils 
import calibration_and_holdout_data 
from lifetimes 
import ParetoNBDFitter 
from lifetimes.plotting 
import plot_history_alive 
from sklearn.metrics 
import mean_squared_error, r2_score import math 
from math import sqrt import re 
temp_data = data.copy() 
#Date Time Analysis 
temp_data.loc[:, "Month"] = data.InvoiceDate.dt.month temp_data.loc[:, 
"Time"] = data.InvoiceDate.dt.time 
temp_data.loc[:, "Year"] = data.InvoiceDate.dt.year 
temp_data.loc[:, "Day"] = data.InvoiceDate.dt.day 
temp_data.loc[:, "Quarter"] = data.InvoiceDate.dt.quarter 
temp_data.loc[:, "Day of Week"] = data.InvoiceDate.dt.dayofweek 
#Mapping day of week 
dayofweek_mapping = dict({0: "Monday", 
1: "Tuesday", 
2: "Wednesday" , 
3: "Thursday", 
4: "Friday", 
5: "Saturday", 
6: "Sunday"}) 
temp_data["Day of Week"] = temp_data["Day of 
Week"].map(dayofweek_mapping) 
plt.figure(figsize=(5,5)) 
plt.pie(ggf_filter["Labels"].value_counts(), labels = 
ggf_filter["Labels"].unique(), startangle = 180, explode = [0.0,1.5,1.5,0.0], 
autopct = "%1.2f%%") 
plt.title("Label Percentage") 
plt.legend() 
ggf_filter.to_csv("customer_segmentation_result.csv
